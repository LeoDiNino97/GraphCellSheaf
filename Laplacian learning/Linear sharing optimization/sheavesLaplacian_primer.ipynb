{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cellular sheaves on graphs \n",
    "## Learning sheaf laplacian through minimum total variation approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a toy-case topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a toy topology for our example\n",
    "\n",
    "nodes = [i for i in range(7)]\n",
    "edges = [\n",
    "    (0,1),\n",
    "    (0,3),\n",
    "    (0,6),\n",
    "    (1,2),\n",
    "    (1,5),\n",
    "    (2,4),\n",
    "    (4,6),\n",
    "    (5,6)\n",
    "]\n",
    "\n",
    "V = 7\n",
    "E = len(edges)\n",
    "\n",
    "d = 20                                          # Node and edges stalks dimension\n",
    "\n",
    "F = {\n",
    "    e:{\n",
    "        e[0]:np.random.randn(d,d),\n",
    "        e[1]:np.random.randn(d,d)\n",
    "        } \n",
    "        for e in edges\n",
    "    }                                           # Incidency linear maps\n",
    "\n",
    "# Sheaf representation \n",
    "\n",
    "# Coboundary map\n",
    "\n",
    "B = np.zeros((d*E, d*V))\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    edge = edges[i]\n",
    "\n",
    "    u = edge[0] \n",
    "    v = edge[1] \n",
    "\n",
    "    B_u = F[edge][u]\n",
    "    B_v = F[edge][v]\n",
    "\n",
    "    B[i*d:(i+1)*d, u*d:(u+1)*d] = B_u\n",
    "    B[i*d:(i+1)*d, v*d:(v+1)*d] = - B_v\n",
    "\n",
    "# Sheaf Laplacian\n",
    "\n",
    "L_f = B.T @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a smooth signals dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(from Hansen J., \"Learning sheaf Laplacians from smooth signals\")* \n",
    "\n",
    "In order to retrieve a dataset of smoothsignals, first of all we sample random gaussians vectors on the nodes of the graph. Then we smooth them according to their expansion in terms of the eigenvectors of the sheaf Laplacian $L_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's firstly define a dataset of random gaussian vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "X = np.random.randn(V*d,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use the Fourier-domain embedded in the Laplacian spectrum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll consider a Tikhonov inspired procedure where we firstly project our dataset over the space spanned by the eigenvectors of the sheaf laplacian: namely $U$ the matrix collecting this eigenvectors we have \n",
    "\\begin{equation}\n",
    "    \\hat{x} = U^T x\n",
    "\\end{equation}\n",
    "\n",
    "So that defining $h(\\lambda) = \\frac{1}{1 + 10\\lambda}$ and $H = \\mathrm{diag}\\{h(\\lambda)\\}_{\\lambda}$, we now have\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{y} = H(\\Lambda) \\hat{x}\n",
    "\\end{equation}\n",
    "\n",
    "and finally our dataset is just reprojected back into the vertex domain:\n",
    "\n",
    "\\begin{equation}\n",
    "    y = U H(\\Lambda) \\hat{x} = U H(\\Lambda) U^T x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda, U = np.linalg.eig(L_f)\n",
    "H = 1/(1 + 10*Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = U @ np.diag(H) @ U.T @ X\n",
    "\n",
    "Y += np.random.normal(0, 10e-2, size=Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628073.0816488669"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(X.T @ L_f @ X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6415.094246945023"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(Y.T @ L_f @ Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our centralized procedure over our toy case topology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:19<00:00,  4.66s/it]\n"
     ]
    }
   ],
   "source": [
    "from controller import learning\n",
    "from itertools import combinations\n",
    "\n",
    "edge_blocks = learning(7, d, Y, 50, 0.5, 10, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now retrieve the energy expressed by each edge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = list(combinations(range(V), 2))\n",
    "\n",
    "energies = {\n",
    "    e : 0\n",
    "    for e in all_edges\n",
    "    }\n",
    "\n",
    "for e in (all_edges):\n",
    "    BB = edge_blocks[e]\n",
    "    u = e[0]\n",
    "    v = e[1]\n",
    "    \n",
    "    '''\n",
    "    X_ = np.zeros_like(X)\n",
    "    X_[u*d:(u+1)*d,:] = X[u*d:(u+1)*d,:]\n",
    "    X_[v*d:(v+1)*d,:] = X[v*d:(v+1)*d,:]\n",
    "    energies[e] = np.linalg.norm(BB @ X_)\n",
    "    '''\n",
    "\n",
    "    energies[e] = np.linalg.norm(BB @ X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll consider the first $E_0$ edges sorted accordingly to their energy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved = sorted(energies.items(), key=lambda x:x[1])[:E]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reconstruct the sheaf laplacian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_ = np.zeros((d*V, d*V))\n",
    "\n",
    "for i in range(E):\n",
    "    edge = retrieved[i][0]\n",
    "\n",
    "    BB_ = edge_blocks[edge]\n",
    "\n",
    "    L_ += BB_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03817704643882571"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The metric chosen by Hansen for the evaluation was the average entry-wise euclidean distance\n",
    "\n",
    "np.sqrt(np.sum((L_f - L_)**2)) / L_f.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the precision of our procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(map(lambda x: x[0], retrieved))).intersection(set(edges))) / E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 3), (0, 6), (1, 2), (1, 5), (2, 4), (4, 6), (5, 6)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 2), 1.613458856152648),\n",
       " ((2, 5), 1.647640810999168),\n",
       " ((2, 6), 1.6601743618745313),\n",
       " ((1, 6), 1.660928897593217),\n",
       " ((1, 5), 1.668288869573076),\n",
       " ((5, 6), 1.6983577918296178),\n",
       " ((4, 6), 1.73089602101169),\n",
       " ((0, 2), 1.736452999389246)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
