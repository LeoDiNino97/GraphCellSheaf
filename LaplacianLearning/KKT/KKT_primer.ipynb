{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a toy-case topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a toy topology for our example\n",
    "\n",
    "nodes = [i for i in range(7)]\n",
    "edges = [\n",
    "    (0,1),\n",
    "    (0,3),\n",
    "    (0,6),\n",
    "    (1,2),\n",
    "    (1,5),\n",
    "    (2,4),\n",
    "    (4,6),\n",
    "    (5,6)\n",
    "]\n",
    "\n",
    "V = 7\n",
    "E = len(edges)\n",
    "\n",
    "d = 3                                           # Node and edges stalks dimension\n",
    "\n",
    "F = {\n",
    "    e:{\n",
    "        e[0]:np.random.randn(d,d),\n",
    "        e[1]:np.random.randn(d,d)\n",
    "        } \n",
    "        for e in edges\n",
    "    }                                           # Incidency linear maps\n",
    "\n",
    "# Sheaf representation \n",
    "\n",
    "# Coboundary map\n",
    "\n",
    "B = np.zeros((d*E, d*V))\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    edge = edges[i]\n",
    "\n",
    "    u = edge[0] \n",
    "    v = edge[1] \n",
    "\n",
    "    B_u = F[edge][u]\n",
    "    B_v = F[edge][v]\n",
    "\n",
    "    B[i*d:(i+1)*d, u*d:(u+1)*d] = B_u\n",
    "    B[i*d:(i+1)*d, v*d:(v+1)*d] = - B_v\n",
    "\n",
    "# Sheaf Laplacian\n",
    "\n",
    "L_f = B.T @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a smooth signals dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(from Hansen J., \"Learning sheaf Laplacians from smooth signals\")* \n",
    "\n",
    "In order to retrieve a dataset of smoothsignals, first of all we sample random gaussians vectors on the nodes of the graph. Then we smooth them according to their expansion in terms of the eigenvectors of the sheaf Laplacian $L_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's firstly define a dataset of random gaussian vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "X = np.random.randn(V*d,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use the Fourier-domain embedded in the Laplacian spectrum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll consider a Tikhonov inspired procedure where we firstly project our dataset over the space spanned by the eigenvectors of the sheaf laplacian: namely $U$ the matrix collecting this eigenvectors we have \n",
    "\\begin{equation}\n",
    "    \\hat{x} = U^T x\n",
    "\\end{equation}\n",
    "\n",
    "So that defining $h(\\lambda) = \\frac{1}{1 + 10\\lambda}$ and $H = \\mathrm{diag}\\{h(\\lambda)\\}_{\\lambda}$, we now have\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{y} = H(\\Lambda) \\hat{x}\n",
    "\\end{equation}\n",
    "\n",
    "and finally our dataset is just reprojected back into the vertex domain:\n",
    "\n",
    "\\begin{equation}\n",
    "    y = U H(\\Lambda) \\hat{x} = U H(\\Lambda) U^T x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda, U = np.linalg.eig(L_f)\n",
    "H = 1/(1 + 10*Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = U @ np.diag(H) @ U.T @ X\n",
    "\n",
    "Y += np.random.normal(0, 10e-2, size=Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14188.90165885626"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(X.T @ L_f @ X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.9963192361668"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(Y.T @ L_f @ Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def premultiplier(Xu, Xv):\n",
    "    uu = np.linalg.inv(Xu @ Xu.T)\n",
    "    uv = Xu @ Xv.T\n",
    "    vv = np.linalg.inv(Xv @ Xv.T)\n",
    "    vu = Xv @ Xu.T\n",
    "\n",
    "    return (uu, uv, vv, vu)\n",
    "\n",
    "def chi_u(uu, uv, vv, vu):\n",
    "\n",
    "    return ((uu @ uv - np.eye(uu.shape[0])) @ vv @ np.linalg.inv(vu @ uu @ uv @ vv - np.eye(uu.shape[0])) @ vu - np.eye(uu.shape[0])) @ uu\n",
    "\n",
    "def chi_v(uu, uv, vv, vu):\n",
    "\n",
    "    return (uu @ uv - np.eye(uu.shape[0])) @ vv @ np.linalg.inv(vu @ uu @ uv @ vv - np.eye(uu.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0\n",
    "\n",
    "maps = {\n",
    "    edge : {\n",
    "        edge[0] : np.zeros((d,d)),\n",
    "        edge[1] : np.zeros((d,d))\n",
    "    }\n",
    "for edge in combinations(nodes, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:00, 2543.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for e in tqdm(combinations(nodes,2)):\n",
    "    u = e[0]\n",
    "    v = e[1]\n",
    "\n",
    "    X_u = Y[u*d:(u+1)*d,:]\n",
    "    X_v = Y[v*d:(v+1)*d,:]\n",
    "    uu, uv, vv, vu = premultiplier(X_u, X_v)\n",
    "\n",
    "    maps[e][u] = chi_u(uu, uv, vv, vu)\n",
    "    maps[e][v] = chi_u(uu, uv, vv, vu)\n",
    "    \n",
    "    T += np.trace(maps[e][u]) + np.trace(maps[e][v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Leonardo\\Documents\\GitHub\\GraphCellSheaf\\LaplacianLearning\\SharingOptimization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'AvgEntryWiseED_L2': 0.10805650154996418, 'AvgEntryWiseED_L1': 0.045605161252548355, 'SparsityAccuracy': 0.625}\n",
      "2 {'AvgEntryWiseED_L2': 0.10805072490471902, 'AvgEntryWiseED_L1': 0.045604747882400536, 'SparsityAccuracy': 0.625}\n",
      "3 {'AvgEntryWiseED_L2': 0.10804109813694904, 'AvgEntryWiseED_L1': 0.04560405892382768, 'SparsityAccuracy': 0.625}\n",
      "4 {'AvgEntryWiseED_L2': 0.1080276227086592, 'AvgEntryWiseED_L1': 0.04560309436433925, 'SparsityAccuracy': 0.625}\n",
      "5 {'AvgEntryWiseED_L2': 0.10801030066775079, 'AvgEntryWiseED_L1': 0.04560185418644692, 'SparsityAccuracy': 0.625}\n",
      "6 {'AvgEntryWiseED_L2': 0.1079891346491165, 'AvgEntryWiseED_L1': 0.04560033836766297, 'SparsityAccuracy': 0.625}\n",
      "7 {'AvgEntryWiseED_L2': 0.10796412787604982, 'AvgEntryWiseED_L1': 0.045598546880498234, 'SparsityAccuracy': 0.625}\n",
      "8 {'AvgEntryWiseED_L2': 0.10793528416196926, 'AvgEntryWiseED_L1': 0.04559647969245968, 'SparsityAccuracy': 0.625}\n",
      "9 {'AvgEntryWiseED_L2': 0.10790260791245875, 'AvgEntryWiseED_L1': 0.04559413676604738, 'SparsityAccuracy': 0.625}\n",
      "10 {'AvgEntryWiseED_L2': 0.1078661041276255, 'AvgEntryWiseED_L1': 0.04559151805875113, 'SparsityAccuracy': 0.625}\n",
      "11 {'AvgEntryWiseED_L2': 0.10782577840477676, 'AvgEntryWiseED_L1': 0.04558862352304664, 'SparsityAccuracy': 0.625}\n",
      "12 {'AvgEntryWiseED_L2': 0.10778163694141732, 'AvgEntryWiseED_L1': 0.04558545310639112, 'SparsityAccuracy': 0.625}\n",
      "13 {'AvgEntryWiseED_L2': 0.10773368653856931, 'AvgEntryWiseED_L1': 0.04558200675121861, 'SparsityAccuracy': 0.625}\n",
      "14 {'AvgEntryWiseED_L2': 0.10768193460441693, 'AvgEntryWiseED_L1': 0.045578284394934686, 'SparsityAccuracy': 0.625}\n",
      "15 {'AvgEntryWiseED_L2': 0.10762638915827791, 'AvgEntryWiseED_L1': 0.045574285969910776, 'SparsityAccuracy': 0.625}\n",
      "16 {'AvgEntryWiseED_L2': 0.10756705883490462, 'AvgEntryWiseED_L1': 0.045570011403478036, 'SparsityAccuracy': 0.625}\n",
      "17 {'AvgEntryWiseED_L2': 0.10750395288911727, 'AvgEntryWiseED_L1': 0.04556546061792071, 'SparsityAccuracy': 0.625}\n",
      "18 {'AvgEntryWiseED_L2': 0.10743708120077188, 'AvgEntryWiseED_L1': 0.04556063353046904, 'SparsityAccuracy': 0.625}\n",
      "19 {'AvgEntryWiseED_L2': 0.10736645428006701, 'AvgEntryWiseED_L1': 0.045555530053291764, 'SparsityAccuracy': 0.625}\n",
      "20 {'AvgEntryWiseED_L2': 0.10729208327319117, 'AvgEntryWiseED_L1': 0.04555015009348806, 'SparsityAccuracy': 0.625}\n",
      "21 {'AvgEntryWiseED_L2': 0.10721397996831582, 'AvgEntryWiseED_L1': 0.04554449355307911, 'SparsityAccuracy': 0.625}\n",
      "22 {'AvgEntryWiseED_L2': 0.10713215680193633, 'AvgEntryWiseED_L1': 0.045538560328999104, 'SparsityAccuracy': 0.625}\n",
      "23 {'AvgEntryWiseED_L2': 0.10704662686556585, 'AvgEntryWiseED_L1': 0.045532350313085855, 'SparsityAccuracy': 0.625}\n",
      "24 {'AvgEntryWiseED_L2': 0.10695740391278537, 'AvgEntryWiseED_L1': 0.0455258633920709, 'SparsityAccuracy': 0.625}\n",
      "25 {'AvgEntryWiseED_L2': 0.10686450236665455, 'AvgEntryWiseED_L1': 0.04551909944756909, 'SparsityAccuracy': 0.625}\n",
      "26 {'AvgEntryWiseED_L2': 0.10676793732748771, 'AvgEntryWiseED_L1': 0.0455120583560678, 'SparsityAccuracy': 0.625}\n",
      "27 {'AvgEntryWiseED_L2': 0.10666772458099943, 'AvgEntryWiseED_L1': 0.04550473998891554, 'SparsityAccuracy': 0.625}\n",
      "28 {'AvgEntryWiseED_L2': 0.10656388060682469, 'AvgEntryWiseED_L1': 0.04549714421231018, 'SparsityAccuracy': 0.625}\n",
      "29 {'AvgEntryWiseED_L2': 0.10645642258741843, 'AvgEntryWiseED_L1': 0.04548927088728664, 'SparsityAccuracy': 0.625}\n",
      "30 {'AvgEntryWiseED_L2': 0.10634536841733955, 'AvgEntryWiseED_L1': 0.04548111986970406, 'SparsityAccuracy': 0.625}\n",
      "31 {'AvgEntryWiseED_L2': 0.10623073671292471, 'AvgEntryWiseED_L1': 0.045472691010232574, 'SparsityAccuracy': 0.625}\n",
      "32 {'AvgEntryWiseED_L2': 0.1061125468223576, 'AvgEntryWiseED_L1': 0.04546398415433955, 'SparsityAccuracy': 0.625}\n",
      "33 {'AvgEntryWiseED_L2': 0.10599081883613855, 'AvgEntryWiseED_L1': 0.045454999142275215, 'SparsityAccuracy': 0.625}\n",
      "34 {'AvgEntryWiseED_L2': 0.10586557359796102, 'AvgEntryWiseED_L1': 0.04544573580905799, 'SparsityAccuracy': 0.625}\n",
      "35 {'AvgEntryWiseED_L2': 0.1057368327160005, 'AvgEntryWiseED_L1': 0.04543619398445917, 'SparsityAccuracy': 0.625}\n",
      "36 {'AvgEntryWiseED_L2': 0.10560461857462158, 'AvgEntryWiseED_L1': 0.04542637349298712, 'SparsityAccuracy': 0.625}\n",
      "37 {'AvgEntryWiseED_L2': 0.10546895434650981, 'AvgEntryWiseED_L1': 0.04541627415387105, 'SparsityAccuracy': 0.625}\n",
      "38 {'AvgEntryWiseED_L2': 0.10532986400523406, 'AvgEntryWiseED_L1': 0.04540589578104413, 'SparsityAccuracy': 0.625}\n",
      "39 {'AvgEntryWiseED_L2': 0.10518737233824627, 'AvgEntryWiseED_L1': 0.045395238183126185, 'SparsityAccuracy': 0.625}\n",
      "40 {'AvgEntryWiseED_L2': 0.10504150496032463, 'AvgEntryWiseED_L1': 0.04538430116340591, 'SparsityAccuracy': 0.625}\n",
      "41 {'AvgEntryWiseED_L2': 0.1048922883274666, 'AvgEntryWiseED_L1': 0.04537308451982242, 'SparsityAccuracy': 0.625}\n",
      "42 {'AvgEntryWiseED_L2': 0.10473974975123897, 'AvgEntryWiseED_L1': 0.045361588044946395, 'SparsityAccuracy': 0.625}\n",
      "43 {'AvgEntryWiseED_L2': 0.10458391741359087, 'AvgEntryWiseED_L1': 0.04534981152596062, 'SparsityAccuracy': 0.625}\n",
      "44 {'AvgEntryWiseED_L2': 0.10442482038213678, 'AvgEntryWiseED_L1': 0.045337754744640024, 'SparsityAccuracy': 0.625}\n",
      "45 {'AvgEntryWiseED_L2': 0.1042624886259163, 'AvgEntryWiseED_L1': 0.0453254174773312, 'SparsityAccuracy': 0.625}\n",
      "46 {'AvgEntryWiseED_L2': 0.10409695303163702, 'AvgEntryWiseED_L1': 0.045312799494931284, 'SparsityAccuracy': 0.625}\n",
      "47 {'AvgEntryWiseED_L2': 0.1039282454204074, 'AvgEntryWiseED_L1': 0.045299900562866376, 'SparsityAccuracy': 0.625}\n",
      "48 {'AvgEntryWiseED_L2': 0.10375639856496634, 'AvgEntryWiseED_L1': 0.045286720441069364, 'SparsityAccuracy': 0.625}\n",
      "49 {'AvgEntryWiseED_L2': 0.10358144620741572, 'AvgEntryWiseED_L1': 0.04527325888395721, 'SparsityAccuracy': 0.625}\n",
      "50 {'AvgEntryWiseED_L2': 0.1034034230774625, 'AvgEntryWiseED_L1': 0.045259515640407644, 'SparsityAccuracy': 0.625}\n",
      "51 {'AvgEntryWiseED_L2': 0.10322236491117683, 'AvgEntryWiseED_L1': 0.04524549045373527, 'SparsityAccuracy': 0.625}\n",
      "52 {'AvgEntryWiseED_L2': 0.10303830847027214, 'AvgEntryWiseED_L1': 0.04523118306166719, 'SparsityAccuracy': 0.625}\n",
      "53 {'AvgEntryWiseED_L2': 0.10285129156191315, 'AvgEntryWiseED_L1': 0.045216593196317864, 'SparsityAccuracy': 0.625}\n",
      "54 {'AvgEntryWiseED_L2': 0.10266135305905798, 'AvgEntryWiseED_L1': 0.045201720584163635, 'SparsityAccuracy': 0.625}\n",
      "55 {'AvgEntryWiseED_L2': 0.10246853292133914, 'AvgEntryWiseED_L1': 0.045186564946016396, 'SparsityAccuracy': 0.625}\n",
      "56 {'AvgEntryWiseED_L2': 0.10227287221648937, 'AvgEntryWiseED_L1': 0.045171356490051585, 'SparsityAccuracy': 0.625}\n",
      "57 {'AvgEntryWiseED_L2': 0.1020744131423164, 'AvgEntryWiseED_L1': 0.045156020783583786, 'SparsityAccuracy': 0.625}\n",
      "58 {'AvgEntryWiseED_L2': 0.10187319904923195, 'AvgEntryWiseED_L1': 0.045141702792141726, 'SparsityAccuracy': 0.625}\n",
      "59 {'AvgEntryWiseED_L2': 0.10166927446333786, 'AvgEntryWiseED_L1': 0.045127231609301946, 'SparsityAccuracy': 0.625}\n",
      "60 {'AvgEntryWiseED_L2': 0.10146268511007399, 'AvgEntryWiseED_L1': 0.045112508294046484, 'SparsityAccuracy': 0.625}\n",
      "61 {'AvgEntryWiseED_L2': 0.10125347793842988, 'AvgEntryWiseED_L1': 0.04509977878258922, 'SparsityAccuracy': 0.625}\n",
      "62 {'AvgEntryWiseED_L2': 0.10104170114572307, 'AvgEntryWiseED_L1': 0.04508919428474177, 'SparsityAccuracy': 0.625}\n",
      "63 {'AvgEntryWiseED_L2': 0.1008274042029453, 'AvgEntryWiseED_L1': 0.045078435135034546, 'SparsityAccuracy': 0.625}\n",
      "64 {'AvgEntryWiseED_L2': 0.10061063788067767, 'AvgEntryWiseED_L1': 0.04506750120838147, 'SparsityAccuracy': 0.625}\n",
      "65 {'AvgEntryWiseED_L2': 0.10039145427557467, 'AvgEntryWiseED_L1': 0.04505639237754211, 'SparsityAccuracy': 0.625}\n",
      "66 {'AvgEntryWiseED_L2': 0.10016990683741604, 'AvgEntryWiseED_L1': 0.0450451085131141, 'SparsityAccuracy': 0.625}\n",
      "67 {'AvgEntryWiseED_L2': 0.09994605039672473, 'AvgEntryWiseED_L1': 0.0450336494835255, 'SparsityAccuracy': 0.625}\n",
      "68 {'AvgEntryWiseED_L2': 0.09971994119294775, 'AvgEntryWiseED_L1': 0.04502201515502687, 'SparsityAccuracy': 0.625}\n",
      "69 {'AvgEntryWiseED_L2': 0.09949163690319555, 'AvgEntryWiseED_L1': 0.045010205391683385, 'SparsityAccuracy': 0.625}\n",
      "70 {'AvgEntryWiseED_L2': 0.09926119667153503, 'AvgEntryWiseED_L1': 0.044998220055366626, 'SparsityAccuracy': 0.625}\n",
      "71 {'AvgEntryWiseED_L2': 0.09902868113882798, 'AvgEntryWiseED_L1': 0.044986059005746384, 'SparsityAccuracy': 0.625}\n",
      "72 {'AvgEntryWiseED_L2': 0.0987941524731079, 'AvgEntryWiseED_L1': 0.044973722100282214, 'SparsityAccuracy': 0.625}\n",
      "73 {'AvgEntryWiseED_L2': 0.09855767440048388, 'AvgEntryWiseED_L1': 0.044961209194214875, 'SparsityAccuracy': 0.625}\n",
      "74 {'AvgEntryWiseED_L2': 0.09831931223656029, 'AvgEntryWiseED_L1': 0.0449485201405576, 'SparsityAccuracy': 0.625}\n",
      "75 {'AvgEntryWiseED_L2': 0.09807913291835817, 'AvgEntryWiseED_L1': 0.044935654790087286, 'SparsityAccuracy': 0.625}\n",
      "76 {'AvgEntryWiseED_L2': 0.09783720503672241, 'AvgEntryWiseED_L1': 0.04492267514739534, 'SparsityAccuracy': 0.625}\n",
      "77 {'AvgEntryWiseED_L2': 0.09759359886919666, 'AvgEntryWiseED_L1': 0.04490983260805143, 'SparsityAccuracy': 0.625}\n",
      "78 {'AvgEntryWiseED_L2': 0.09734838641334559, 'AvgEntryWiseED_L1': 0.04489805816109611, 'SparsityAccuracy': 0.625}\n",
      "79 {'AvgEntryWiseED_L2': 0.09710164142050105, 'AvgEntryWiseED_L1': 0.04488868394090723, 'SparsityAccuracy': 0.625}\n",
      "80 {'AvgEntryWiseED_L2': 0.0968534394299071, 'AvgEntryWiseED_L1': 0.04487918830826984, 'SparsityAccuracy': 0.625}\n",
      "81 {'AvgEntryWiseED_L2': 0.09660385780323452, 'AvgEntryWiseED_L1': 0.04486957118610131, 'SparsityAccuracy': 0.625}\n",
      "82 {'AvgEntryWiseED_L2': 0.09635297575943384, 'AvgEntryWiseED_L1': 0.04485983249626628, 'SparsityAccuracy': 0.625}\n",
      "83 {'AvgEntryWiseED_L2': 0.09610087440989137, 'AvgEntryWiseED_L1': 0.04484997215957343, 'SparsityAccuracy': 0.625}\n",
      "84 {'AvgEntryWiseED_L2': 0.09584763679385017, 'AvgEntryWiseED_L1': 0.044839990095772116, 'SparsityAccuracy': 0.625}\n",
      "85 {'AvgEntryWiseED_L2': 0.09559334791405377, 'AvgEntryWiseED_L1': 0.044829886223549116, 'SparsityAccuracy': 0.625}\n",
      "86 {'AvgEntryWiseED_L2': 0.09533809477256665, 'AvgEntryWiseED_L1': 0.04481966046052517, 'SparsityAccuracy': 0.625}\n",
      "87 {'AvgEntryWiseED_L2': 0.09508196640672138, 'AvgEntryWiseED_L1': 0.04480931272325157, 'SparsityAccuracy': 0.625}\n",
      "88 {'AvgEntryWiseED_L2': 0.09482505392513822, 'AvgEntryWiseED_L1': 0.04479884292720666, 'SparsityAccuracy': 0.625}\n",
      "89 {'AvgEntryWiseED_L2': 0.0945674505437579, 'AvgEntryWiseED_L1': 0.04478825098679229, 'SparsityAccuracy': 0.625}\n",
      "90 {'AvgEntryWiseED_L2': 0.09430925162182408, 'AvgEntryWiseED_L1': 0.04477753681533022, 'SparsityAccuracy': 0.625}\n",
      "91 {'AvgEntryWiseED_L2': 0.09405055469774662, 'AvgEntryWiseED_L1': 0.04476670032505851, 'SparsityAccuracy': 0.625}\n",
      "92 {'AvgEntryWiseED_L2': 0.09379145952477154, 'AvgEntryWiseED_L1': 0.04475574142712777, 'SparsityAccuracy': 0.625}\n",
      "93 {'AvgEntryWiseED_L2': 0.09353206810637828, 'AvgEntryWiseED_L1': 0.044744660031597466, 'SparsityAccuracy': 0.625}\n",
      "94 {'AvgEntryWiseED_L2': 0.09327248473131865, 'AvgEntryWiseED_L1': 0.04473345604743208, 'SparsityAccuracy': 0.625}\n",
      "95 {'AvgEntryWiseED_L2': 0.09301281600820646, 'AvgEntryWiseED_L1': 0.04472212938249728, 'SparsityAccuracy': 0.625}\n",
      "96 {'AvgEntryWiseED_L2': 0.09275317089956034, 'AvgEntryWiseED_L1': 0.04471067994355603, 'SparsityAccuracy': 0.625}\n",
      "97 {'AvgEntryWiseED_L2': 0.0924936607551954, 'AvgEntryWiseED_L1': 0.04469910763626458, 'SparsityAccuracy': 0.625}\n",
      "98 {'AvgEntryWiseED_L2': 0.09223439934485346, 'AvgEntryWiseED_L1': 0.04468741236516854, 'SparsityAccuracy': 0.625}\n",
      "99 {'AvgEntryWiseED_L2': 0.09197550288995437, 'AvgEntryWiseED_L1': 0.04467809493271503, 'SparsityAccuracy': 0.625}\n"
     ]
    }
   ],
   "source": [
    "for N in range(1,100):\n",
    "    maps_ = {\n",
    "        edge : {\n",
    "            edge[0] : N/T * maps[edge][edge[0]],\n",
    "            edge[1] : N/T * maps[edge][edge[1]]\n",
    "        }\n",
    "        for edge in combinations(nodes, 2)\n",
    "    }\n",
    "    print(N,reconstructed_laplacian_metrics(len(nodes), edges, d, maps_, Y, L_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
